{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {
        "id": "MXXTuy_o0sjk"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U kaggle_environments"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from kaggle_environments import make, evaluate"
      ],
      "metadata": {
        "id": "yz23vWHD0wcj"
      },
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Опишем поведение агента, всегда играющего \"камень\" - это значение 0"
      ],
      "metadata": {
        "id": "0kuo6IOxiRub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Записываем код агента в файл.\n",
        "%%writefile rock_agent.py\n",
        "\n",
        "#Example of the simple agent\n",
        "#0 - rock\n",
        "#1 - paper\n",
        "#2 - scissors\n",
        "def rock_agent(observation, configuration):\n",
        "    return 0"
      ],
      "metadata": {
        "id": "bqTqV7B92rJ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91f3a120-67b4-4b8a-9381-195c26ade254"
      },
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting rock_agent.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Попробуем теперь использовать информацию о прошлых действиях противника. Опишем агента, который производит то же самое действие, что и оппонент на прошлом ходу"
      ],
      "metadata": {
        "id": "et1J5hUGigeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Записываем код агента в файл.\n",
        "%%writefile copy_opponent.py\n",
        "\n",
        "# Импортируем модуль случайных чисел.\n",
        "import random\n",
        "\n",
        "#Example\n",
        "def copy_opponent(observation, configuration):\n",
        "    #in case we have information about opponent last move\n",
        "    if observation.step > 0:\n",
        "        return observation.lastOpponentAction\n",
        "    #initial step\n",
        "    else:\n",
        "        return random.randrange(0, configuration.signs)"
      ],
      "metadata": {
        "id": "7l6Ttw6qi0jk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0f1e3c3-860a-44dc-aff4-83b3fcb184be"
      },
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting copy_opponent.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Воспользуемся функцией evaluate из библиотеки kaggle_environments с помощью которой запустим наших агентов и проведем эксперимент на заданном количестве игр"
      ],
      "metadata": {
        "id": "ExgIpXUVjbjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(\n",
        "    \"rps\", #environment to use - no need to change\n",
        "    [\"rock_agent.py\", \"copy_opponent.py\"], #agents to evaluate\n",
        "    configuration={\"episodeSteps\": 100} #number of episodes\n",
        ")"
      ],
      "metadata": {
        "id": "wv6Ip6M004xa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fab16dd0-8647-4e06-c9e8-b20e15c00975"
      },
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(\n",
        "    \"rps\", #environment to use - no need to change\n",
        "    [\"rock_agent.py\", \"paper\"], #agents to evaluate\n",
        "    configuration={\"episodeSteps\": 100} #number of episodes\n",
        ")"
      ],
      "metadata": {
        "id": "FC6_QWe9k3rr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e78cb0e-6dc1-421d-beff-72e9e83aa480"
      },
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[-99.0, 99.0]]"
            ]
          },
          "metadata": {},
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Опишем поведение агента, всегда играющего \"бумага\" - это значение 1"
      ],
      "metadata": {
        "id": "JN1vcperQE9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Записываем код агента в файл.\n",
        "%%writefile paper_agent.py\n",
        "\n",
        "# Обявляем функцию агента.\n",
        "def paper_agent(observation, configuration):\n",
        "    # Возвращаем значение бумаги.\n",
        "    return 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR6oZnXhQDcx",
        "outputId": "719f5d08-2ea0-4092-ec0f-7af4c7dd82c7"
      },
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting paper_agent.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(\n",
        "    \"rps\", #environment to use - no need to change\n",
        "    [\"paper_agent.py\", \"statistical\"], #agents to evaluate\n",
        "    configuration={\"episodeSteps\": 100} #number of episodes\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGi5xbt0dDmY",
        "outputId": "c313786b-810c-4b3e-e785-0180162b93db"
      },
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[-97.0, 97.0]]"
            ]
          },
          "metadata": {},
          "execution_count": 257
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Опишем поведение агента, всегда играющего \"ножницы\" - это значение 2"
      ],
      "metadata": {
        "id": "YYeiiOTiQggs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Записываем код агента в файл.\n",
        "%%writefile scissors_agent.py\n",
        "\n",
        "# Обявляем функцию агента.\n",
        "def scissors_agent(observation, configuration):\n",
        "    # Возвращаем значение ножниц.\n",
        "    return 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0M-yy83cQgKg",
        "outputId": "06c0f127-250d-4127-94a7-f15bae3d2f61"
      },
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting scissors_agent.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(\n",
        "    \"rps\", #environment to use - no need to change\n",
        "    [\"scissors_agent.py\", \"reactionary\"], #agents to evaluate\n",
        "    configuration={\"episodeSteps\": 100} #number of episodes\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjeqdsF2bjMm",
        "outputId": "8b50a036-6648-4f2a-bcd0-a950328b0b56"
      },
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[-99.0, 99.0]]"
            ]
          },
          "metadata": {},
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Опишем поведение агента, всегда играющего случайное значение"
      ],
      "metadata": {
        "id": "beT836TZQf6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Записываем код агента в файл.\n",
        "%%writefile random_agent.py\n",
        "\n",
        "# Импортируем модуль случайных чисел.\n",
        "import random\n",
        "\n",
        "# Обявляем функцию агента.\n",
        "def random_agent(observation, configuration):\n",
        "    # Возвращаем случайное значение.\n",
        "    return random.randrange(0, configuration.signs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6Kj2rRzRQJ9",
        "outputId": "f5450f69-c5a7-453d-90d3-31c4274fc8a1"
      },
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting random_agent.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(\n",
        "    \"rps\", #environment to use - no need to change\n",
        "    [\"random_agent.py\", \"random_agent.py\"], #agents to evaluate\n",
        "    configuration={\"episodeSteps\": 100} #number of episodes\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SZFqIGSb9wy",
        "outputId": "1144c9e5-0eb1-42cb-9b46-88918ed70574"
      },
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 261
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Опишем поведение агента, всегда случайно выбирающего \"бумагу\" или \"ножницы\"\n"
      ],
      "metadata": {
        "id": "hw_wLJqMd5jA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Записываем код агента в файл.\n",
        "%%writefile paper_scissors_agent.py\n",
        "\n",
        "# Импортируем модуль случайных чисел.\n",
        "import random\n",
        "\n",
        "# Обявляем функцию агента.\n",
        "def paper_scissors_agent(observation, configuration):\n",
        "    # Возвращаем значение ножниц или бумаги.\n",
        "    return random.choice([1,2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQ9OKeVDeQdi",
        "outputId": "c43f1e8e-3b0f-4436-c56f-892120dbcf2c"
      },
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting paper_scissors_agent.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(\n",
        "    \"rps\", #environment to use - no need to change\n",
        "    [\"paper_scissors_agent.py\", \"random_agent.py\"], #agents to evaluate\n",
        "    configuration={\"episodeSteps\": 100} #number of episodes\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ri2ahIl-e0Lw",
        "outputId": "c205876b-e173-4e42-d3bf-a72e11cc89df"
      },
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Опишем поведение агента, всегда случайно выбирающего \"бумагу\" или \"камень\""
      ],
      "metadata": {
        "id": "S65a-z5PfwOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Записываем код агента в файл.\n",
        "%%writefile paper_rock_agent.py\n",
        "\n",
        "# Импортируем модуль случайных чисел.\n",
        "import random\n",
        "\n",
        "# Обявляем функцию агента.\n",
        "def paper_rock_agent(observation, configuration):\n",
        "    # Возвращаем значение бумаги или камня.\n",
        "    return random.choice([0,1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d3keT5sfwqs",
        "outputId": "22931e24-1ba6-4979-e6b9-3725b904ed76"
      },
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting paper_rock_agent.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(\n",
        "    \"rps\", #environment to use - no need to change\n",
        "    [\"paper_rock_agent.py\", \"paper_agent.py\"], #agents to evaluate\n",
        "    configuration={\"episodeSteps\": 100} #number of episodes\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4owy1rXQgB91",
        "outputId": "bf9cca54-2a0d-498f-e56f-cc8d315b6cab"
      },
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[-49.0, 49.0]]"
            ]
          },
          "metadata": {},
          "execution_count": 267
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Опишем поведение агента, всегда случайно выбирающего \"ножницы\" или \"камень\""
      ],
      "metadata": {
        "id": "GqxJa7cdgXW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Записываем код агента в файл.\n",
        "%%writefile scissors_rock_agent.py\n",
        "\n",
        "# Импортируем модуль случайных чисел.\n",
        "import random\n",
        "\n",
        "# Обявляем функцию агента.\n",
        "def scissors_rock_agent(observation, configuration):\n",
        "    # Возвращаем значение ножниц или камня.\n",
        "    return random.choice([0,2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlCcQ8magie9",
        "outputId": "9c2b095a-cca4-4887-f6c7-00d89e69b432"
      },
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting scissors_rock_agent.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(\n",
        "    \"rps\", #environment to use - no need to change\n",
        "    [\"scissors_rock_agent.py\", \"rock_agent.py\"], #agents to evaluate\n",
        "    configuration={\"episodeSteps\": 100} #number of episodes\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZl35A3Hi5Fv",
        "outputId": "53d15e3c-3185-4c49-b779-7bb1e1d61be9"
      },
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[-51.0, 51.0]]"
            ]
          },
          "metadata": {},
          "execution_count": 269
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Опишем поведение агента, который случайно выбирает то, что не выбрал противник на прошлом ходу"
      ],
      "metadata": {
        "id": "f161yK5PMgFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Записываем код агента в файл.\n",
        "%%writefile random_opposit_agent.py\n",
        "\n",
        "# Импортируем модуль случайных чисел.\n",
        "import random\n",
        "\n",
        "# Обявляем функцию агента.\n",
        "def random_opposit_agent(observation, configuration):\n",
        "    # Если ход не первый\n",
        "    if observation.step > 0:\n",
        "        # случайно возвращаем то, что не выбрал противник на прошлом ходу.\n",
        "        if observation.lastOpponentAction == 0:\n",
        "            return random.choice([1,2])\n",
        "        elif observation.lastOpponentAction == 1:\n",
        "            return random.choice([0,2])\n",
        "        else:\n",
        "            return random.choice([1,0])\n",
        "    # Если ход первый возвращаем случайное значение.\n",
        "    else:\n",
        "        return random.randrange(0, configuration.signs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhwsDhs9Mzfj",
        "outputId": "9859bd2a-bdc0-42a4-d132-4399c8f57734"
      },
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting random_opposit_agent.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(\n",
        "    \"rps\", #environment to use - no need to change\n",
        "    [\"random_agent.py\", \"random_opposit_agent.py\"], #agents to evaluate\n",
        "    configuration={\"episodeSteps\": 100} #number of episodes\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Q3U3_D3NqAa",
        "outputId": "26523be2-031e-4c07-e04f-524651994e09"
      },
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 272
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Опишем поведение агента, который выбирает следующее в списке действие относительно того, что использовал оппонент на прошлом ходу, если список закончился обращаемся к началу списка."
      ],
      "metadata": {
        "id": "Zo4bryveUJCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Записываем код агента в файл.\n",
        "%%writefile next_opponent.py\n",
        "\n",
        "# Импортируем модуль случайных чисел.\n",
        "import random\n",
        "\n",
        "# Обявляем функцию агента.\n",
        "def next_opponent(observation, configuration):\n",
        "    # Если ход не первый\n",
        "    if observation.step > 0:\n",
        "        # возвращаем следующее в списке значение последнего действия.\n",
        "        return (observation.lastOpponentAction + 1) % configuration.signs\n",
        "    # Если ход первый возвращаем случайное значение.\n",
        "    else:\n",
        "        return random.randrange(0, configuration.signs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVk6YZBoV2J2",
        "outputId": "56d0202f-a32d-4921-f08f-0f2288085e64"
      },
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting next_opponent.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(\n",
        "    \"rps\", #environment to use - no need to change\n",
        "    [\"next_opponent.py\", \"statistical\"], #agents to evaluate\n",
        "    configuration={\"episodeSteps\": 100} #number of episodes\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pm1B8A_ZWNCi",
        "outputId": "cd4fa76e-82a3-4b27-bc2c-9d5125cb7ee4"
      },
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[49.0, -49.0]]"
            ]
          },
          "metadata": {},
          "execution_count": 275
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Опишем поведение агента, который выбирает предыдущее в списке действие относительно того, что использовал оппонент на прошлом ходу, если оппонент выбрал первое действие в списке, агент выбирает последнее."
      ],
      "metadata": {
        "id": "4tYjg_x0XBp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Записываем код агента в файл.\n",
        "%%writefile previous_opponent.py\n",
        "\n",
        "# Импортируем модуль случайных чисел.\n",
        "import random\n",
        "\n",
        "# Обявляем функцию агента.\n",
        "def previous_opponent(observation, configuration):\n",
        "    # Если ход не первый\n",
        "    if observation.step > 0:\n",
        "        # возвращаем предыдущее в списке значение последнего действия.\n",
        "        return (observation.lastOpponentAction + 2) % configuration.signs\n",
        "    # Если ход первый возвращаем случайное значение.\n",
        "    else:\n",
        "        return random.randrange(0, configuration.signs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPODKu2XX8zH",
        "outputId": "7dbfe288-5605-4063-8339-bcb6936164f1"
      },
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting previous_opponent.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(\n",
        "    \"rps\", #environment to use - no need to change\n",
        "    [\"previous_opponent.py\", \"next_opponent.py\"], #agents to evaluate\n",
        "    configuration={\"episodeSteps\": 100} #number of episodes\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2RfNqeAYGlq",
        "outputId": "0a96420a-b6b2-4a38-ccb5-b0c5d5dd8f0d"
      },
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[-99.0, 99.0]]"
            ]
          },
          "metadata": {},
          "execution_count": 278
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Опишем поведение агента, который последовательно перебирает список вариантов, начиная с первого элемента, если список закончился, первый ход случайный."
      ],
      "metadata": {
        "id": "mUVGz0ODcf9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Записываем код агента в файл.\n",
        "%%writefile sequence_agent.py\n",
        "\n",
        "# Импортируем модуль случайных чисел.\n",
        "import random\n",
        "\n",
        "# Создаем переменную для записи последнего хода агента.\n",
        "lastAction = None\n",
        "\n",
        "# Обявляем функцию агента.\n",
        "def sequence_agent(observation, configuration):\n",
        "    # Сообщаем, что используем глобальную переменную.\n",
        "    global lastAction\n",
        "    # Если ход не первый\n",
        "    if observation.step > 0:\n",
        "        # зписываем значение следующего действия в списке.\n",
        "        lastAction = (lastAction + 1) % configuration.signs\n",
        "    # Если ход первый записывем случайное значение.\n",
        "    else:\n",
        "        lastAction = random.randrange(0, configuration.signs)\n",
        "    # Возвращаем полученное значение\n",
        "    return lastAction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwc29iMhcgYj",
        "outputId": "be70f91a-63ad-4d47-af2a-e04b32cdab53"
      },
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting sequence_agent.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(\n",
        "    \"rps\", #environment to use - no need to change\n",
        "    [\"sequence_agent.py\", \"previous_opponent.py\"], #agents to evaluate\n",
        "    configuration={\"episodeSteps\": 100}, #number of episodes\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZmzFe8Acl4G",
        "outputId": "2fac58e8-36cc-48a2-b7f8-8ffc6a2728fc"
      },
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[-97.0, 97.0]]"
            ]
          },
          "metadata": {},
          "execution_count": 280
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. Опишем поведение агента, который последовательно перебирает список вариантов в обратном направлении, первый ход случайный."
      ],
      "metadata": {
        "id": "K8l2cqbsjiSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Записываем код агента в файл.\n",
        "%%writefile revsequence_agent.py\n",
        "\n",
        "# Импортируем модуль случайных чисел.\n",
        "import random\n",
        "\n",
        "# Создаем переменную для записи последнего хода агента.\n",
        "lastAction = None\n",
        "\n",
        "# Обявляем функцию агента.\n",
        "def revsequence_agent(observation, configuration):\n",
        "    # Сообщаем, что используем глобальную переменную.\n",
        "    global lastAction\n",
        "    # Если ход не первый записывем предыдущее значение из списка.\n",
        "    if observation.step > 0:\n",
        "        lastAction = (lastAction + 2) % configuration.signs\n",
        "    # Если ход первый записывем случайное значение.\n",
        "    else:\n",
        "        lastAction = random.randrange(0, configuration.signs)\n",
        "    # Возвращаем полученное значение\n",
        "    return lastAction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAkHnReXji4Q",
        "outputId": "914f8b91-aae9-4826-eeea-ce7e6bd422fd"
      },
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting revsequence_agent.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(\n",
        "    \"rps\", #environment to use - no need to change\n",
        "    [\"revsequence_agent.py\", \"next_opponent.py\"], #agents to evaluate\n",
        "    configuration={\"episodeSteps\": 100}, #number of episodes\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHGoxIJOk6n_",
        "outputId": "75ac9a0c-dbca-43cf-9bd6-bd93756c631d"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[98.0, -98.0]]"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. Опишем поведение агента, который выбирает ход отличный от последнего своего и оппонента, случайным образом если последние ходы обоих игроков совпадают."
      ],
      "metadata": {
        "id": "NFK31RckABCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Записываем код агента в файл.\n",
        "%%writefile two_opposite_agent.py\n",
        "\n",
        "# Импортируем модуль случайных чисел.\n",
        "import random\n",
        "\n",
        "# Создаем переменную для записи последнего хода агента.\n",
        "lastAction = None\n",
        "\n",
        "# Обявляем функцию агента.\n",
        "def two_opposite_agent(observation, configuration):\n",
        "    # Сообщаем, что используем глобальную переменную.\n",
        "    global lastAction\n",
        "    # Создаем список значений ходов.\n",
        "    lst = [0, 1, 2]\n",
        "    # Если ход не первый\n",
        "    if observation.step > 0:\n",
        "        # и ходы агента и оппонента совпадают\n",
        "        if lastAction==observation.lastOpponentAction:\n",
        "            # убираем из списка соответствующи один элемент.\n",
        "            lst.remove(lastAction)\n",
        "        # Иначе убираем из списка ходы агента и оппонента.\n",
        "        else:\n",
        "          lst.remove(observation.lastOpponentAction)\n",
        "          lst.remove(lastAction)\n",
        "        # Записываем случайное значение из оставшихся в списке элементов.\n",
        "        lastAction=random.choice(lst)\n",
        "    # Первый ход делаем случайным образом.\n",
        "    else:\n",
        "        lastAction = random.randrange(0, configuration.signs)\n",
        "    # Возвращаем полученное значение\n",
        "    return lastAction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x-nMzX3AqaS",
        "outputId": "964018d9-921d-484b-8528-d21ea97f5490"
      },
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting two_opposite_agent.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(\n",
        "    \"rps\", #environment to use - no need to change\n",
        "    [\"two_opposite_agent.py\", \"revsequence_agent.py\"], #agents to evaluate\n",
        "    configuration={\"episodeSteps\": 100}, #number of episodes\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHpeb6-HDrzm",
        "outputId": "b8d03ced-0a99-44e2-8aa3-bef2e15575c4"
      },
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[-98.0, 98.0]]"
            ]
          },
          "metadata": {},
          "execution_count": 286
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. Опишем поведение агента, который выбирает ход случайным образом между своим последним ходом и последним ходом оппонента."
      ],
      "metadata": {
        "id": "LKmypQzdEhVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Записываем код агента в файл.\n",
        "%%writefile two_opponent_agent.py\n",
        "\n",
        "# Импортируем модуль случайных чисел.\n",
        "import random\n",
        "\n",
        "# Создаем переменную для записи последнего хода агента.\n",
        "lastAction = None\n",
        "\n",
        "# Объявляем функцию агента.\n",
        "def two_opponent_agent(observation, configuration):\n",
        "    # Сообщаем, что используем глобальную переменную.\n",
        "    global lastAction\n",
        "    # На всех ходах после первого случайно выбираем значение последнего хода.\n",
        "    if observation.step > 0:\n",
        "        lastAction=random.choice([lastAction,observation.lastOpponentAction])\n",
        "    # Первый ход делаем случайным образом.\n",
        "    else:\n",
        "        lastAction = random.randrange(0, configuration.signs)\n",
        "    # Возвращаем полученное значение\n",
        "    return lastAction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HE64qOImFAq8",
        "outputId": "c6c0eb12-01fe-4fb4-9c65-5274fd8f58c4"
      },
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting two_opponent_agent.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(\n",
        "    \"rps\", #environment to use - no need to change\n",
        "    [\"two_opponent_agent.py\", \"next_opponent.py\"], #agents to evaluate\n",
        "    configuration={\"episodeSteps\": 100}, #number of episodes\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kz-H-mefGPqM",
        "outputId": "9e4a2516-8622-47b3-b13e-3acbbce081f9"
      },
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[-63.0, 63.0]]"
            ]
          },
          "metadata": {},
          "execution_count": 288
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Турнир\n",
        "Составим список агентов, потом организуем их поочередную игру результат запишем в словарь и выведем на экран."
      ],
      "metadata": {
        "id": "MWlnH1GCG4Eq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cоставляем список агентов.\n",
        "agents = ['rock_agent.py',\n",
        "          'copy_opponent.py',\n",
        "          'paper_agent.py',\n",
        "          'scissors_agent.py',\n",
        "          'random_agent.py',\n",
        "          'paper_scissors_agent.py',\n",
        "          'paper_rock_agent.py',\n",
        "          'scissors_rock_agent.py',\n",
        "          'random_opposit_agent.py',\n",
        "          'next_opponent.py',\n",
        "          'previous_opponent.py',\n",
        "          'sequence_agent.py',\n",
        "          'revsequence_agent.py',\n",
        "          'two_opposite_agent.py',\n",
        "          'two_opponent_agent.py'\n",
        "          ]\n",
        "\n",
        "# Cоздаем словарь для турнирной таблицы, ключи - агенты, значения - 0.\n",
        "rank = {agent: 0 for agent in agents}\n",
        "\n",
        "# Pапускаем турнир с момощью двух вложенных циклов.\n",
        "# Каждый агент соревнуется с остальными.\n",
        "for i in range(len(agents)):\n",
        "    for j in range(i+1, len(agents)):\n",
        "        # Запускаем состязание между i и j агентами записываем его результат.\n",
        "        e = evaluate(\n",
        "        \"rps\", #environment to use - no need to change\n",
        "        [agents[i], agents[j]], #agents to evaluate\n",
        "        configuration={\"episodeSteps\": 100} #number of episodes\n",
        "        )\n",
        "        # Определяем победителя, записываем очки в словарь.\n",
        "        if e[0][0] > e[0][1]:\n",
        "            rank[agents[i]] += 1 # Начисляем очко если победил i\n",
        "        elif e[0][0] < e[0][1]:\n",
        "            rank[agents[j]] += 1 # Начисляем очко если победил j\n",
        "\n",
        "# Определяем лучшую стратегию, выводим результат.\n",
        "print(f'Лучшая стратегия: {max(rank, key=rank.get)}')\n",
        "# Сортируем словарь - турнирную таблицу.\n",
        "stdrank=dict(sorted(rank.items(), key=lambda x: (-x[1],x[0])))\n",
        "# Запускаем цикл по элементам словаря, выводим турнирную таблицу.\n",
        "for agent in stdrank:\n",
        "    print(agent,\"_\"*(40-len(agent)),stdrank[agent])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9dr8QjrKXc8",
        "outputId": "86c8501e-ef48-4afe-e46a-7f11ccb54e1d"
      },
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшая стратегия: next_opponent.py\n",
            "next_opponent.py ________________________ 7\n",
            "paper_agent.py __________________________ 3\n",
            "paper_rock_agent.py _____________________ 3\n",
            "revsequence_agent.py ____________________ 3\n",
            "rock_agent.py ___________________________ 3\n",
            "scissors_agent.py _______________________ 3\n",
            "two_opposite_agent.py ___________________ 3\n",
            "copy_opponent.py ________________________ 2\n",
            "paper_scissors_agent.py _________________ 2\n",
            "previous_opponent.py ____________________ 2\n",
            "scissors_rock_agent.py __________________ 2\n",
            "sequence_agent.py _______________________ 2\n",
            "two_opponent_agent.py ___________________ 2\n",
            "random_opposit_agent.py _________________ 1\n",
            "random_agent.py _________________________ 0\n"
          ]
        }
      ]
    }
  ]
}